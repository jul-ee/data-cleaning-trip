## 📋 Trip 데이터 정제 프로젝트 (Data Cleaning)

본 프로젝트는 택시 이용 내역 데이터를 기반으로  
다양한 변수들을 활용하여 “택시 요금”을 예측한다는 가정하에 데이터를 정제하는 것을 목표로 합니다.

> 🛠 사용 환경: &nbsp;Python, Pandas, Jupyter Notebook

<br>

## 프로젝트 목표

- 데이터 분석 전 필수 단계인 데이터 정제 흐름을 실제 데이터에 적용하며 익히기
- 결측치, 이상치, 중복 데이터 처리 및 문자열/날짜형 데이터 처리 실습
- Pandas 메서드와 시각화를 활용하여 데이터 분포 및 정제 과정에 대한 이해도 높이기

<br>

## 분석 프로세스

|  | 내용 | 주요 메서드 |
|------|------|------------------|
| 1 | 데이터 로드 및 구조 확인 | `read_csv()`, `info()`, `describe()` |
| 2 | 중복 데이터 처리 | `drop_duplicates()` |
| 3 | 결측치 처리 | `isna()`, `dropna()` |
| 4 | 이상치 탐지 및 처리 | `sns.scatterplot()`, `apply()`, `quantile()`, 조건 필터링 |
| 5 | 텍스트 데이터 처리 | `replace()`, `.str.split()`, `.str` |
| 6 | 날짜 데이터 처리 | `pd.to_datetime()`, `.dt` |
| 7 | Feature Engineering | 연산식 기반 생성, 시간 변수 활용 |

<br>
<br>

## 💡 인사이트 및 결론

- 데이터를 확인하는 과정에서 결측치 및 이상치를 판단하기 위해 도메인에 대한 이해도가 필요한 것을 실감했다.
  
  → &nbsp;해당 데이터셋은 컬럼명이 직관적이어서 분석이 수월했지만, 도메인 이해 없이 단정하기 어려운 경우가 많을 수 있음을 느꼈다.

- 필요에 따라 결측치 및 이상치를 처리하기 전에 중복 데이터를 먼저 제거해야 하는 경우가 발생할 수도 있다.

- 데이터가 충분히 크고, 결측치가 많지 않다면 결측치를 채워서 노이즈가 끼게 되는 것보다는 제거하는 것이 나을 수 있다.
  
- `scatterplot()`을 활용해 전체 데이터 분포를 시각화함으로써, 단순 수치 기반 필터링보다 직관적으로 이상치를 탐지할 수 있다.

- travel_time(총 이동 시간)과 같은 새로운 변수를 생성함으로써, 기존 raw 데이터에서는 보이지 않던 패턴을 반영할 수 있다.

  → &nbsp;특히 `tpep_pickup_datetime`, `tpep_dropoff_datetime`을 활용한 시간 차 계산은 유용한 파생변수 생성 방식임을 체감했다.

<br>

> 본 프로젝트는 택시 운행 데이터를 기반으로 데이터 로드 → 정제 → 피처 엔지니어링의 흐름을 체계적으로 학습하고,  
> 이후 요금 예측 모델 개발로 확장할 수 있는 기반을 다지는 데 중점을 두었습니다.



